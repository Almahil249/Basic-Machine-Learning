{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# include libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as ListedColormap\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load iris Dataset and plot its data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "data = iris.data\n",
    "target = iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot data  <Axes: xlabel='sepal_length', ylabel='sepal_width'>\n",
    "plt.scatter(data[:,0], data[:,1], c=target)\n",
    "plt.xlabel('sepal_length')\n",
    "plt.ylabel('sepal_width')\n",
    "plt.show()\n",
    "##plot data  <Axes: label='petal_length', label='petal_width'>\n",
    "plt.scatter(iris.data[:,2], iris.data[:,3], c=target)\n",
    "plt.xlabel('petal_length')\n",
    "plt.ylabel('petal_width')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_test_split function implementation with 30% testRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data,labels,testRatio=0.3):\n",
    "    n=len(data)\n",
    "    testSize=int(n*testRatio)\n",
    "    testIndices=np.random.choice(n,testSize,replace=False)\n",
    "    trainIndices=[i for i in range(n) if i not in testIndices]\n",
    "    return data[trainIndices],data[testIndices],labels[trainIndices],labels[testIndices]\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test =train_test_split(data,target)\n",
    "\n",
    "\n",
    "import warnings\n",
    "def versiontuple(version):\n",
    "   return tuple(map(int, (version.split(\".\"))))\n",
    "def decision_plot(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "   # setup marker generator and color map\n",
    "   markers = ('s', 'x', 'o', '^', 'v')\n",
    "   colors = ('red', 'blue', 'green', 'gray', 'cyan')\n",
    "   cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "   # plot the decision surface\n",
    "   x1min, x1max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "   x2min, x2max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "   xx1, xx2 = np.meshgrid(np.arange(x1min, x1max, resolution),\n",
    "                 np.arange(x2min, x2max, resolution))\n",
    "   Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "   Z = Z.reshape(xx1.shape)\n",
    "   plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "   plt.xlim(xx1.min(), xx1.max())\n",
    "   plt.ylim(xx2.min(), xx2.max())\n",
    "   for idx, cl in enumerate(np.unique(y)):\n",
    "      plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "              alpha=0.8, c=cmap(idx),\n",
    "              marker=markers[idx], label=cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plot 2 graphs of the  X_train and X_test to see the distribution graph 1: sepal_length vs sepal_width graph 2: petal_length vs petal_width\n",
    "\n",
    "plt.scatter(X_train[:,0],X_train[:,1],label='Train Data')\n",
    "plt.scatter(X_test[:,0],X_test[:,1],label='Test Data')\n",
    "plt.xlabel('sepal_length')\n",
    "plt.ylabel('sepal_width')\n",
    "plt.title('sepal length width - Train / Test data distribution')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(X_train[:,2],X_train[:,3],label='Train Data')\n",
    "plt.scatter(X_test[:,2],X_test[:,3],label='Test Data')\n",
    "plt.xlabel('petal_length')\n",
    "plt.ylabel('petal_width')\n",
    "plt.title('petal length width - Train / Test data distribution')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#plotting the data y_train and y_test to see the distribution\n",
    "plt.scatter(y_train,X_train[:,1],label='Train Data')\n",
    "plt.scatter(y_test,X_test[:,1],label='Test Data')\n",
    "plt.title('Labels - Train / Test data distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaussianNB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train[:, :2], y_train) # \"sepal length and sepal width\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mesh grid for plotting decision boundariesS\n",
    "h = 0.02  # step size in the mesh\n",
    "mesh_x1, mesh_x2 = np.meshgrid(np.arange(min(X_train[:, 0]) - h, max(X_train[:, 0]) + h, h),\n",
    "                               np.arange(min(X_train[:, 1]) - h, max(X_train[:, 1]) + h, h))\n",
    "\n",
    "# Create a new array of points\n",
    "mesh_points = np.c_[mesh_x1.ravel(), mesh_x2.ravel()]\n",
    "\n",
    "# Predict class labels for mesh points\n",
    "y_pred = clf.predict(mesh_points)\n",
    "\n",
    "# Plot the decision boundaries\n",
    "light_cmap = plt.colormaps['Reds']\n",
    "plt.contourf(mesh_x1, mesh_x2, y_pred.reshape(mesh_x1.shape), cmap=light_cmap, alpha=0.4)\n",
    "\n",
    "# Plot data points\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=light_cmap, edgecolors='k', s=20, label='Training points')\n",
    "\n",
    "# Plot iris flower species labels\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[1])\n",
    "plt.title('Naive Bayes Decision Boundaries - Iris Dataset')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#plotting the decision boundaries for the petal length and petal width\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train[:, 2:], y_train) # \"petal length and petal width\"\n",
    "\n",
    "# Define 2 mesh grid for plotting decision boundaries\n",
    "h = 0.02  # step size in the mesh\n",
    "mesh_x1, mesh_x2 = np.meshgrid(np.arange(min(X_train[:, 2]) - h, max(X_train[:, 2]) + h, h),\n",
    "                               np.arange(min(X_train[:, 3]) - h, max(X_train[:, 3]) + h, h))\n",
    "\n",
    "# Create a new array of points\n",
    "mesh_points = np.c_[mesh_x1.ravel(), mesh_x2.ravel()]\n",
    "\n",
    "# Predict class labels for mesh points\n",
    "y_pred = clf.predict(mesh_points)\n",
    "\n",
    "# Plot the decision boundaries\n",
    "light_cmap = plt.colormaps['Reds']\n",
    "plt.contourf(mesh_x1, mesh_x2, y_pred.reshape(mesh_x1.shape), cmap=light_cmap, alpha=0.4)\n",
    "\n",
    "# Plot data points\n",
    "plt.scatter(X_train[:, 2], X_train[:, 3], c=y_train, cmap=light_cmap, edgecolors='k', s=20, label='Training points')\n",
    "\n",
    "# Plot iris flower species labels\n",
    "plt.xlabel(iris.feature_names[2])\n",
    "plt.ylabel(iris.feature_names[3])\n",
    "plt.title('Naive Bayes Decision Boundaries - Iris Dataset')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate_accuracy function implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predicted_y,y):\n",
    "    return sum(predicted_y==y)/len(y)\n",
    "\n",
    "clf.fit(X_train , y_train)\n",
    "\n",
    "print(\"Model Accuracy= \", calculate_accuracy(clf.predict(X_test),y_test)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = datasets.load_iris()\n",
    "# We'll use the petal length and width only for this analysis\n",
    "X = iris_data.data[:, [2, 3]]\n",
    "y = iris_data.target\n",
    "# Input the iris data into the pandas dataframe\n",
    "iris_dataframe = pd.DataFrame(iris_data.data[:, [2, 3]],\n",
    "                  columns=iris_data.feature_names[2:])\n",
    "# View the first 5 rows of the data\n",
    "print(iris_dataframe.head())\n",
    "# Print the unique labels of the dataset\n",
    "print('\\n' + 'Unique Labels contained in this data are '\n",
    "     + str(np.unique(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, 0.3)\n",
    "print('The training set contains {} samples and the test set contains {} samples'.format(X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Standard_Scaler = StandardScaler()\n",
    "Standard_Scaler.fit(X_train)\n",
    "X_train_standard = Standard_Scaler.transform(X_train) #X_train\n",
    "X_test_standard = Standard_Scaler.transform(X_test) #X_test\n",
    "\n",
    "SVM = SVC(kernel='rbf', C=1.0, random_state=0, gamma=0.1)\n",
    "SVM.fit(X_train_standard, y_train)\n",
    "print('The accuracy of the SVM classifier on the training data is {:.2f}'.format(SVM.score(X_train_standard, y_train)))\n",
    "print('The accuracy of the SVM classifier on the test data is {:.2f}'.format(SVM.score(X_test_standard, y_test)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the decision boundaries\n",
    "h = 0.02  # step size in the mesh\n",
    "x_min, x_max = X_train_standard[:, 0].min() - 1, X_train_standard[:, 0].max() + 1\n",
    "y_min, y_max = X_train_standard[:, 1].min() - 1, X_train_standard[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = SVM.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "plt.scatter(X_train_standard[y_train == 0, 0], X_train_standard[y_train == 0, 1], c='r', marker='^', label='0')\n",
    "plt.scatter(X_train_standard[y_train == 1, 0], X_train_standard[y_train == 1, 1], c='b', marker='o', label='1')\n",
    "plt.scatter(X_train_standard[y_train == 2, 0], X_train_standard[y_train == 2, 1], c='g', marker='s', label='2')\n",
    "plt.xlabel('Petal Length')\n",
    "plt.ylabel('Petal Width')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('SVM Decision Boundaries - Iris Dataset')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = datasets.load_iris()\n",
    "# We'll use the petal length and width only for this analysis\n",
    "X = iris_data.data[:, [0, 1]]\n",
    "y = iris_data.target\n",
    "# Input the iris data into the pandas dataframe\n",
    "iris_dataframe = pd.DataFrame(iris_data.data[:, [0, 1]],\n",
    "                  columns=iris_data.feature_names[:2])\n",
    "# View the first 5 rows of the data\n",
    "print(iris_dataframe.head())\n",
    "# Print the unique labels of the dataset\n",
    "print('\\n' + 'Unique Labels contained in this data are '\n",
    "     + str(np.unique(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, 0.3)\n",
    "print('The training set contains {} samples and the test set contains {} samples'.format(X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Standard_Scaler = StandardScaler()\n",
    "Standard_Scaler.fit(X_train)\n",
    "X_train_standard = X_train #Standard_Scaler.transform(X_train) #\n",
    "X_test_standard = X_test #Standard_Scaler.transform(X_test) #\n",
    "\n",
    "SVM = SVC(kernel='rbf', C=1.0, random_state=0, gamma=0.1)\n",
    "SVM.fit(X_train_standard, y_train)\n",
    "print('The accuracy of the SVM classifier on the training data is {:.2f}'.format(SVM.score(X_train_standard, y_train)))\n",
    "print('The accuracy of the SVM classifier on the test data is {:.2f}'.format(SVM.score(X_test_standard, y_test)))\n",
    "\n",
    "#plotting the decision boundaries for the sepal length and sepal width\n",
    "h = 0.02  # step size in the mesh\n",
    "x_min, x_max = X_train_standard[:, 0].min() - 1, X_train_standard[:, 0].max() + 1\n",
    "y_min, y_max = X_train_standard[:, 1].min() - 1, X_train_standard[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = SVM.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "plt.scatter(X_train_standard[y_train == 0, 0], X_train_standard[y_train == 0, 1], c='r', marker='^', label='0')\n",
    "plt.scatter(X_train_standard[y_train == 1, 0], X_train_standard[y_train == 1, 1], c='b', marker='o', label='1')\n",
    "plt.scatter(X_train_standard[y_train == 2, 0], X_train_standard[y_train == 2, 1], c='g', marker='s', label='2')\n",
    "plt.xlabel('Sepal Length')\n",
    "plt.ylabel('Sepal Width')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('SVM Decision Boundaries - Iris Dataset')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
